import gradio as gr
import os
import sys
import threading
import time
from typing import Optional, List, Dict, Any

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from components import (
    FileUploadComponent,
    ProgressDisplayComponent,
    ConfigManagerComponent,
    HistoryManagerComponent,
    BatchProcessorComponent
)
from model import OpenAIModel, GLMModel
from translator import PDFTranslator
from utils import LOG

class TranslatorGUI:
    """ç¿»è¯‘åº”ç”¨ä¸»GUIç±»"""
    
    def __init__(self):
        # åˆå§‹åŒ–ç»„ä»¶
        self.file_upload = FileUploadComponent()
        self.progress_display = ProgressDisplayComponent()
        self.config_manager = ConfigManagerComponent()
        self.history_manager = HistoryManagerComponent()
        self.batch_processor = BatchProcessorComponent()
        
        # å½“å‰ç¿»è¯‘çŠ¶æ€
        self.current_translator = None
        self.is_translating = False
        self.current_record_id = None
        self.progress_status = ""
        self.progress_overall = 0
        self.progress_page = 0
        self.progress_time = ""

    def create_interface(self):
        """åˆ›å»ºä¸»ç•Œé¢"""
        with gr.Blocks(
            title="AI PDF ç¿»è¯‘å™¨",
            theme=gr.themes.Soft(),
            css=self._get_custom_css()
        ) as interface:
            
            # æ ‡é¢˜å’Œæè¿°
            gr.Markdown(
                """
                # ğŸ¤– AI PDF ç¿»è¯‘å™¨
                
                **åŠŸèƒ½ç‰¹ç‚¹:**
                - ğŸ¯ æ”¯æŒå¤šç§AIæ¨¡å‹ (OpenAI GPT, ChatGLM)
                - ğŸ“ æ‹–æ‹½å¼æ–‡ä»¶ä¸Šä¼ ï¼Œæ”¯æŒæ‰¹é‡å¤„ç†
                - ğŸ“Š å®æ—¶ç¿»è¯‘è¿›åº¦æ˜¾ç¤º
                - ğŸ“š ç¿»è¯‘å†å²è®°å½•ç®¡ç†
                - âš™ï¸ çµæ´»çš„é…ç½®ç®¡ç†
                """
            )
            
            with gr.Tabs() as tabs:
                # å•æ–‡ä»¶ç¿»è¯‘æ ‡ç­¾é¡µ
                with gr.Tab("ğŸ“„ å•æ–‡ä»¶ç¿»è¯‘", id="single_translate"):
                    self._create_single_translate_tab()
                    
                # æ‰¹é‡ç¿»è¯‘æ ‡ç­¾é¡µ  
                with gr.Tab("ğŸ“ æ‰¹é‡ç¿»è¯‘", id="batch_translate"):
                    self._create_batch_translate_tab()
                    
                # é…ç½®ç®¡ç†æ ‡ç­¾é¡µ
                with gr.Tab("âš™ï¸ é…ç½®ç®¡ç†", id="config"):
                    self._create_config_tab()
                    
                # å†å²è®°å½•æ ‡ç­¾é¡µ
                with gr.Tab("ğŸ“š ç¿»è¯‘å†å²", id="history"):
                    self._create_history_tab()
                    
        return interface
    
    def _create_single_translate_tab(self):
        """åˆ›å»ºå•æ–‡ä»¶ç¿»è¯‘æ ‡ç­¾é¡µ"""
        with gr.Row():
            with gr.Column(scale=1):
                # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
                single_file, file_info = self.file_upload.create_single_upload_interface()
                
                # ç¿»è¯‘è®¾ç½®
                with gr.Group():
                    gr.Markdown("### ğŸ¯ ç¿»è¯‘è®¾ç½®")
                    
                    target_language = gr.Dropdown(
                        choices=['ä¸­æ–‡', 'è‹±æ–‡', 'æ—¥æ–‡', 'éŸ©æ–‡', 'æ³•æ–‡', 'å¾·æ–‡', 'è¥¿ç­ç‰™æ–‡'],
                        label="ç›®æ ‡è¯­è¨€",
                        value='ä¸­æ–‡'
                    )
                    
                    file_format = gr.Dropdown(
                        choices=['markdown', 'pdf'],
                        label="è¾“å‡ºæ ¼å¼",
                        value='markdown'
                    )
                    
                    model_type = gr.Dropdown(
                        choices=['OpenAI', 'ChatGLM'],
                        label="AIæ¨¡å‹",
                        value='OpenAI'
                    )
                    
                # ç¿»è¯‘æŒ‰é’®
                translate_btn = gr.Button(
                    "ğŸš€ å¼€å§‹ç¿»è¯‘",
                    variant="primary",
                    size="lg"
                )
                
            with gr.Column(scale=1):
                # è¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
                progress_components = self.progress_display.create_progress_interface()
                
                # ç»“æœæ˜¾ç¤º
                with gr.Group():
                    gr.Markdown("### ğŸ“¥ ç¿»è¯‘ç»“æœ")
                    
                    result_file = gr.File(
                        label="ä¸‹è½½ç¿»è¯‘ç»“æœ",
                        interactive=False
                    )
                    
                    result_info = gr.Textbox(
                        label="ç¿»è¯‘ä¿¡æ¯",
                        interactive=False,
                        lines=3
                    )
        
        # ç»‘å®šäº‹ä»¶
        single_file.change(
            fn=self.file_upload.get_file_info,
            inputs=[single_file],
            outputs=[file_info]
        )
        
        translate_btn.click(
            fn=self._start_single_translation,
            inputs=[single_file, target_language, file_format, model_type],
            outputs=[result_file, result_info] + list(progress_components)
        )
    
    def _create_batch_translate_tab(self):
        """åˆ›å»ºæ‰¹é‡ç¿»è¯‘æ ‡ç­¾é¡µ"""
        with gr.Row():
            with gr.Column(scale=1):
                # æ‰¹é‡æ–‡ä»¶ä¸Šä¼ 
                batch_files, batch_file_info = self.file_upload.create_batch_upload_interface()
                
                # æ‰¹é‡è®¾ç½®
                with gr.Group():
                    gr.Markdown("### âš™ï¸ æ‰¹é‡è®¾ç½®")
                    
                    batch_target_language = gr.Dropdown(
                        choices=['ä¸­æ–‡', 'è‹±æ–‡', 'æ—¥æ–‡', 'éŸ©æ–‡', 'æ³•æ–‡', 'å¾·æ–‡', 'è¥¿ç­ç‰™æ–‡'],
                        label="ç›®æ ‡è¯­è¨€",
                        value='ä¸­æ–‡'
                    )
                    
                    batch_file_format = gr.Dropdown(
                        choices=['markdown', 'pdf'],
                        label="è¾“å‡ºæ ¼å¼",
                        value='markdown'
                    )
                    
                    batch_model_type = gr.Dropdown(
                        choices=['OpenAI', 'ChatGLM'],
                        label="AIæ¨¡å‹",
                        value='OpenAI'
                    )
                
                # æ‰¹é‡æ“ä½œæŒ‰é’®
                add_to_queue_btn = gr.Button("â• æ·»åŠ åˆ°é˜Ÿåˆ—", variant="secondary")
                
            with gr.Column(scale=2):
                # æ‰¹é‡å¤„ç†ç»„ä»¶
                batch_components, batch_buttons = self.batch_processor.create_batch_interface()
        
        # ç»‘å®šæ‰¹é‡å¤„ç†äº‹ä»¶
        batch_files.change(
            fn=self.file_upload.validate_batch_files,
            inputs=[batch_files],
            outputs=[batch_file_info]
        )
        
        add_to_queue_btn.click(
            fn=self._add_files_to_batch_queue,
            inputs=[batch_files, batch_target_language, batch_file_format, batch_model_type],
            outputs=[batch_components['batch_status'], batch_components['queue_display']]
        )
        
        batch_buttons['start_batch_btn'].click(
            fn=self._start_batch_processing,
            inputs=[batch_components['max_workers'], batch_components['retry_failed'], batch_components['max_retries']],
            outputs=[batch_components['batch_status']]
        )
    
    def _create_config_tab(self):
        """åˆ›å»ºé…ç½®ç®¡ç†æ ‡ç­¾é¡µ"""
        config_components, config_buttons = self.config_manager.create_config_interface()
        
        # ç»‘å®šé…ç½®ç®¡ç†äº‹ä»¶
        config_buttons['load_config_btn'].click(
            fn=self._load_config,
            outputs=list(config_components.values())
        )
        
        config_buttons['save_config_btn'].click(
            fn=self._save_config,
            inputs=list(config_components.values())[:-1],  # é™¤äº†status
            outputs=[config_components['config_status']]
        )
        
        config_buttons['reset_config_btn'].click(
            fn=self._reset_config,
            outputs=list(config_components.values())
        )
    
    def _create_history_tab(self):
        """åˆ›å»ºå†å²è®°å½•æ ‡ç­¾é¡µ"""
        history_components, history_buttons = self.history_manager.create_history_interface()
        
        # ç»‘å®šå†å²è®°å½•äº‹ä»¶
        history_buttons['refresh_btn'].click(
            fn=self._refresh_history,
            outputs=[history_components['history_list'], history_components['stats_info']]
        )
        
        history_buttons['clear_btn'].click(
            fn=self._clear_history,
            outputs=[history_components['history_list'], history_components['stats_info']]
        )
        
        history_components['history_list'].select(
            fn=self._select_history_record,
            outputs=[history_components['selected_info']]
        )
    
    def _start_single_translation(self, 
                                file_obj,  # æ”¹ä¸ºæ¥æ”¶æ–‡ä»¶å¯¹è±¡
                                target_language: str,
                                file_format: str,
                                model_type: str):
        """å¼€å§‹å•æ–‡ä»¶ç¿»è¯‘"""
        # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—
        LOG.debug(f"æ¥æ”¶åˆ°çš„æ–‡ä»¶å¯¹è±¡: {file_obj}")
        LOG.debug(f"æ–‡ä»¶å¯¹è±¡ç±»å‹: {type(file_obj)}")
        
        # å¤„ç†æ–‡ä»¶å¯¹è±¡
        if file_obj is None:
            LOG.warning("æ–‡ä»¶å¯¹è±¡ä¸ºNone")
            yield None, "è¯·å…ˆé€‰æ‹©è¦ç¿»è¯‘çš„PDFæ–‡ä»¶", *[None] * 4
            return
        
        # è·å–æ–‡ä»¶è·¯å¾„
        try:
            file_path = file_obj.name if hasattr(file_obj, 'name') else str(file_obj)
            LOG.debug(f"è§£æçš„æ–‡ä»¶è·¯å¾„: {file_path}")
        except Exception as e:
            LOG.error(f"æ–‡ä»¶è·¯å¾„è§£æå¤±è´¥: {e}")
            yield None, "æ–‡ä»¶è·¯å¾„è§£æå¤±è´¥ï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶", *[None] * 4
            return
        
        # éªŒè¯æ–‡ä»¶
        if not file_path or not os.path.exists(file_path):
            LOG.warning(f"æ–‡ä»¶è·¯å¾„æ— æ•ˆ: {file_path}")
            yield None, "æ–‡ä»¶è·¯å¾„æ— æ•ˆï¼Œè¯·é‡æ–°é€‰æ‹©æ–‡ä»¶", *[None] * 4
            return

        is_valid, message = self.file_upload.validate_file(file_path)
        if not is_valid:
            LOG.warning(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {message}")
            yield None, f"æ–‡ä»¶éªŒè¯å¤±è´¥: {message}", *[None] * 4
            return

        try:
            config = self.config_manager.load_config()
            model = OpenAIModel(model=config['OpenAIModel']['model'], api_key=config['OpenAIModel']['api_key']) if model_type == 'OpenAI' else GLMModel(model_url=config['GLMModel']['model_url'], timeout=config['GLMModel']['timeout'])
            translator = PDFTranslator(model)
            
            record_id = self.history_manager.add_record(input_file=file_path, target_language=target_language, status="è¿›è¡Œä¸­")
            self.is_translating = True
            self.current_record_id = record_id

            def progress_callback(page_num, content_idx, total_contents):
                if self.progress_display.start_time is None:
                    self.progress_display.initialize_progress(len(translator.book.pages))
                
                progress_data = self.progress_display.update_page_progress(page_num, content_idx, total_contents)
                self.progress_overall = progress_data['overall_progress']
                self.progress_page = progress_data['page_progress']
                self.progress_status = progress_data['status_message']
                self.progress_time = progress_data['time_info']

            def translate_worker():
                try:
                    base_name = os.path.splitext(os.path.basename(file_path))[0]
                    output_dir = config.get('common', {}).get('output_dir', './output')
                    os.makedirs(output_dir, exist_ok=True)
                    output_file = os.path.join(output_dir, f"{base_name}_translated.{file_format}")
                    
                    translator.translate_pdf(file_path, file_format, target_language, output_file, progress_callback=progress_callback)
                    
                    self.history_manager.update_record(record_id, status="å®Œæˆ", output_file=output_file)
                    self.final_result = (output_file, "ç¿»è¯‘å®Œæˆï¼")
                except Exception as e:
                    error_msg = str(e)
                    LOG.error(f"ç¿»è¯‘å¤±è´¥: {error_msg}")
                    self.history_manager.update_record(record_id, status="å¤±è´¥", error_message=error_msg)
                    self.final_result = (None, f"ç¿»è¯‘å¤±è´¥: {error_msg}")
                finally:
                    self.is_translating = False

            thread = threading.Thread(target=translate_worker)
            thread.start()

            while self.is_translating:
                yield None, "ç¿»è¯‘è¿›è¡Œä¸­...", self.progress_overall, self.progress_page, self.progress_status, self.progress_time
                time.sleep(0.1)

            yield self.final_result[0], self.final_result[1], 100, 100, "ç¿»è¯‘å®Œæˆ", self.progress_time

        except Exception as e:
            error_msg = str(e)
            LOG.error(f"å¯åŠ¨ç¿»è¯‘å¤±è´¥: {error_msg}")
            yield None, f"å¯åŠ¨ç¿»è¯‘å¤±è´¥: {error_msg}", *[None] * 4
    
    def _add_files_to_batch_queue(self,
                                file_paths: List[str],
                                target_language: str,
                                file_format: str,
                                model_type: str):
        """æ·»åŠ æ–‡ä»¶åˆ°æ‰¹é‡å¤„ç†é˜Ÿåˆ—"""
        if not file_paths:
            return "è¯·å…ˆé€‰æ‹©è¦ç¿»è¯‘çš„æ–‡ä»¶", []
            
        # éªŒè¯æ–‡ä»¶
        valid_files, info_message = self.file_upload.validate_batch_files(file_paths)
        
        if not valid_files:
            return info_message, []
            
        # å‡†å¤‡é…ç½®
        config = {
            'target_language': target_language,
            'file_format': file_format,
            'model_type': model_type
        }
        
        # æ·»åŠ åˆ°é˜Ÿåˆ—
        result_message = self.batch_processor.add_files_to_queue(valid_files, config)
        queue_data = self.batch_processor.get_queue_display_data()
        
        return result_message, queue_data
    
    def _start_batch_processing(self, max_workers: int, retry_failed: bool, max_retries: int):
        """å¼€å§‹æ‰¹é‡å¤„ç†"""
        def batch_translate_function(**kwargs):
            # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„ç¿»è¯‘å‡½æ•°
            # ç®€åŒ–å®ç°ï¼Œè¿”å›æˆåŠŸç»“æœ
            return {'success': True, 'output_file': 'dummy_output.md'}
        
        result = self.batch_processor.start_batch_processing(
            translate_function=batch_translate_function,
            max_workers=int(max_workers),
            retry_failed=retry_failed,
            max_retries=int(max_retries)
        )
        
        return result
    
    def _load_config(self):
        """åŠ è½½é…ç½®"""
        config = self.config_manager.load_config()
        updated_values = self.config_manager.update_components_from_config(config)
        
        return (
            updated_values['openai_model'],
            updated_values['openai_api_key'],
            updated_values['glm_model_url'],
            updated_values['glm_timeout'],
            updated_values['target_language'],
            updated_values['file_format'],
            updated_values['output_dir'],
            "é…ç½®åŠ è½½æˆåŠŸ"
        )
    
    def _save_config(self, *config_values):
        """ä¿å­˜é…ç½®"""
        # å°†Gradioç»„ä»¶å€¼è½¬æ¢ä¸ºé…ç½®å­—å…¸
        config_dict = {
            'openai_model': config_values[0],
            'openai_api_key': config_values[1],
            'glm_model_url': config_values[2],
            'glm_timeout': config_values[3],
            'target_language': config_values[4],
            'file_format': config_values[5],
            'output_dir': config_values[6]
        }
        
        config_data = self.config_manager.get_config_from_components(config_dict)
        
        # éªŒè¯é…ç½®
        is_valid, message = self.config_manager.validate_config(config_data)
        if not is_valid:
            return message
            
        # ä¿å­˜é…ç½®
        success, message = self.config_manager.save_config(config_data)
        return message
    
    def _reset_config(self):
        """é‡ç½®é…ç½®"""
        default_values = self.config_manager.update_components_from_config(
            self.config_manager.default_config
        )
        
        return (
            default_values['openai_model'],
            default_values['openai_api_key'],
            default_values['glm_model_url'],
            default_values['glm_timeout'],
            default_values['target_language'],
            default_values['file_format'],
            default_values['output_dir'],
            "é…ç½®å·²é‡ç½®ä¸ºé»˜è®¤å€¼"
        )
    
    def _refresh_history(self):
        """åˆ·æ–°å†å²è®°å½•"""
        self.history_manager.history_data = self.history_manager.load_history()
        table_data = self.history_manager.get_history_table_data()
        stats = self.history_manager.get_statistics()
        
        return table_data, stats
    
    def _clear_history(self):
        """æ¸…ç©ºå†å²è®°å½•"""
        self.history_manager.clear_history()
        return [], "å†å²è®°å½•å·²æ¸…ç©º"
    
    def _select_history_record(self, evt: gr.SelectData):
        """é€‰æ‹©å†å²è®°å½•"""
        if evt.index is not None:
            details = self.history_manager.get_record_details(evt.index[0])
            return details
        return "æœªé€‰æ‹©è®°å½•"
    
    def _get_custom_css(self) -> str:
        """è·å–è‡ªå®šä¹‰CSSæ ·å¼"""
        return """
        .gradio-container {
            max-width: 1200px !important;
        }
        
        .gr-button {
            border-radius: 8px;
        }
        
        .gr-form {
            border-radius: 12px;
            border: 1px solid #e1e5e9;
        }
        
        .gr-panel {
            border-radius: 12px;
        }
        
        .progress-container {
            margin: 10px 0;
        }
        """

def launch_gui(share: bool = False, server_name: str = "127.0.0.1", server_port: int = 7860):
    """å¯åŠ¨GUIåº”ç”¨"""
    try:
        app = TranslatorGUI()
        interface = app.create_interface()
        
        LOG.info(f"å¯åŠ¨GUIåº”ç”¨: http://{server_name}:{server_port}")
        
        interface.launch(
            share=share,
            server_name=server_name,
            server_port=server_port,
            show_error=True,
            quiet=False
        )
        
    except Exception as e:
        LOG.error(f"å¯åŠ¨GUIå¤±è´¥: {str(e)}")
        raise

if __name__ == "__main__":
    launch_gui()
